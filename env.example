# LiteLLM Master Key (required!)
# Generate key with: openssl rand -base64 32
# Make sure the key starts with "sk-"
LITELLM_MASTER_KEY=sk-your-master-key-here

# ══════════════════════════════════════════════════════════
# LiteLLM Admin UI Credentials (for cost tracking dashboard)
# ══════════════════════════════════════════════════════════
# Access LiteLLM Admin UI at the port configured during setup (shown after startup)
# IMPORTANT: Use UI_USERNAME and UI_PASSWORD (without LITELLM_ prefix)
# IMPORTANT: Be sure to change these!
UI_USERNAME=admin
UI_PASSWORD=change_this_password_123

# PostgreSQL settings
POSTGRES_USER=litellm
POSTGRES_PASSWORD=litellm_password
POSTGRES_DB=litellm
POSTGRES_PORT=5432

# Service ports
LITELLM_PORT=4000
WEBUI_PORT=3000

# ══════════════════════════════════════════════════════════
# API Keys for LLM Providers
# ══════════════════════════════════════════════════════════
# LiteLLM supports 100+ providers. See: https://docs.litellm.ai/docs/providers
# API keys can be added here or configured via LiteLLM Admin UI
# 
# NOTE: API keys are NOT required for setup/start - you can add them later
# through LiteLLM Admin UI at http://localhost:4000/ui

# Anthropic Claude API
ANTHROPIC_API_KEY=your-anthropic-api-key-here
# Get key: https://console.anthropic.com/

# OpenAI GPT models
# OPENAI_API_KEY=your-openai-api-key-here
# Get key: https://platform.openai.com/api-keys

# Google AI Studio (Gemini)
# GEMINI_API_KEY=your-gemini-api-key-here
# GOOGLE_API_KEY=your-google-api-key-here  # Alternative
# Get key: https://makersuite.google.com/app/apikey

# Groq (fast inference)
# GROQ_API_KEY=your-groq-api-key-here
# Get key: https://console.groq.com/keys

# Deepseek
# DEEPSEEK_API_KEY=your-deepseek-api-key-here
# Get key: https://deepseek.com/

# Mistral AI
# MISTRAL_API_KEY=your-mistral-api-key-here
# Get key: https://console.mistral.ai/

# Together AI
# TOGETHER_API_KEY=your-together-api-key-here
# Get key: https://together.ai/

# Perplexity AI
# PERPLEXITY_API_KEY=your-perplexity-api-key-here
# Get key: https://www.perplexity.ai

# xAI (Grok)
# XAI_API_KEY=your-xai-api-key-here
# Get key: https://docs.x.ai/docs

# Cohere
# COHERE_API_KEY=your-cohere-api-key-here
# Get key: https://cohere.com/

# Fireworks AI
# FIREWORKS_API_KEY=your-fireworks-api-key-here
# Get key: https://fireworks.ai/

# OpenRouter (access to multiple models)
# OPENROUTER_API_KEY=your-openrouter-api-key-here
# Get key: https://openrouter.ai/

# Azure OpenAI (requires additional config)
# AZURE_API_KEY=your-azure-api-key-here
# AZURE_API_BASE=https://your-resource.openai.azure.com/
# AZURE_API_VERSION=2024-02-15-preview

# For complete list of providers and environment variables, see:
# https://docs.litellm.ai/docs/providers

# Open WebUI Secret Key (optional, for security)
# Generate with: openssl rand -base64 32
WEBUI_SECRET_KEY=

# ══════════════════════════════════════════════════════════
# Open WebUI Web Search Configuration
# ══════════════════════════════════════════════════════════
# NOTE: Web Search settings are AUTOMATICALLY configured based on your resource profile
# during setup. These values are defaults that can be overridden via .env file.
#
# Profile-specific defaults (optimized for multi-user environments).
# The stack now relies on API providers that return extracted content (no Playwright).
#   Small VPS (2GB RAM):  WEB_SEARCH_CONCURRENT_REQUESTS=1, WEB_SEARCH_RESULT_COUNT=1
#   Medium VPS (4GB RAM): WEB_SEARCH_CONCURRENT_REQUESTS=1, WEB_SEARCH_RESULT_COUNT=1
#   Large VPS (8GB+ RAM): WEB_SEARCH_CONCURRENT_REQUESTS=2, WEB_SEARCH_RESULT_COUNT=3
#   Desktop:              WEB_SEARCH_CONCURRENT_REQUESTS=3, WEB_SEARCH_RESULT_COUNT=4
#
# Web Search Engine options:
#   tavily - RECOMMENDED for AI/LLM use cases, better accuracy, requires API key (free tier available)
#   google_pse - Good accuracy, requires Google API key and setup
#   serper - Good for technical queries, requires API key
#   brave - Good privacy, requires API key
#   kagi - Good results, requires API key (paid)
#
# RECOMMENDATION: For better accuracy, use tavily (free tier: 1000 searches/month)
#   Get API key: https://tavily.com/
#   Set: WEB_SEARCH_ENGINE=tavily
#   Set: TAVILY_API_KEY=your-api-key-here
#
# NOTE: Playwright/web loader is NOT bundled anymore. Engines that only return URLs
# (e.g. ddgs) will not work out-of-the-box.
# See: https://openwebui.codelin.vip/en/getting-started/env-configuration/
WEB_SEARCH_ENGINE=tavily

# Tavily API Key (required if WEB_SEARCH_ENGINE=tavily)
# Get free API key at: https://tavily.com/
# Free tier: 1000 searches/month
TAVILY_API_KEY=

# Google PSE API Key (required if WEB_SEARCH_ENGINE=google_pse)
# Setup: https://programmablesearchengine.google.com/
GOOGLE_PSE_API_KEY=

# Serper API Key (required if WEB_SEARCH_ENGINE=serper)
# Get API key at: https://serper.dev/
SERPER_API_KEY=

# Concurrent requests for web search (automatically set by profile, can override here)
# Small VPS/Medium VPS: 1, Large VPS: 2, Desktop: 3
WEB_SEARCH_CONCURRENT_REQUESTS=

# Number of search results to fetch (automatically set by profile, can override here)
# Small VPS/Medium VPS: 1, Large VPS: 3, Desktop: 4
WEB_SEARCH_RESULT_COUNT=

# Bypass web loader (Playwright). Default is true because the loader is not bundled.
# Only set to "false" if you run your own scraping engine elsewhere and wire it up manually.
BYPASS_WEB_SEARCH_WEB_LOADER=true

# Flag to update OpenWebUI web search settings from environment variables on next start
# Set to "yes" automatically when profile is changed during setup
# Will be cleared automatically after successful update
# You can manually set this to "yes" if you want to force update on next start
UPDATE_WEB_SEARCH_SETTINGS=no

# ══════════════════════════════════════════════════════════
# LiteLLM Docker Image Configuration
# ══════════════════════════════════════════════════════════
# Official repository: https://github.com/BerriAI/litellm
# Default: main-stable (matches official docker-compose config)
# WARNING: main-latest may have Prisma migration loop bug (infinite baseline_diff migrations)
# 
# Recommended - Official GitHub Container Registry (stable version, default):
#   LITELLM_IMAGE_REPO=ghcr.io/berriai/litellm
#   LITELLM_IMAGE_TAG=main-stable
# 
# Alternative - Official GitHub Container Registry (specific version):
#   LITELLM_IMAGE_REPO=ghcr.io/berriai/litellm
#   LITELLM_IMAGE_TAG=main-1.50.0
# 
# Docker Hub (verify official status before using):
#   LITELLM_IMAGE_REPO=litellm/litellm
#   LITELLM_IMAGE_TAG=v1.79.3-stable
# 
# Check available tags:
#   - Official (GitHub): https://github.com/orgs/BerriAI/packages/container/litellm
#   - Docker Hub: https://hub.docker.com/r/litellm/litellm/tags (verify official status)
# 
# Leave empty to use defaults: ghcr.io/berriai/litellm:main-stable
LITELLM_IMAGE_REPO=
LITELLM_IMAGE_TAG=
