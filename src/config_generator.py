"""
Configuration file (config.yaml) generation
Generates minimal config with only general_settings.
Models are configured through LiteLLM Admin UI.
"""

import os
from .utils import print_success
from .budgets import get_general_budget


def generate_config_yaml(budget_profile: str = "test") -> None:
    """
    Generate minimal config.yaml file with only general_settings.
    Models should be added through LiteLLM Admin UI.
    
    Args:
        budget_profile: Budget profile name ('test', 'prod', or 'unlimited')
    
    Raises:
        ValidationError: If budget_profile is invalid
        FileOperationError: If file cannot be written
    """
    from .core.exceptions import ValidationError
    from .core.constants import (
        BUDGET_PROFILE_TEST, BUDGET_PROFILE_PROD, BUDGET_PROFILE_UNLIMITED
    )
    
    # Validation
    valid_profiles = (BUDGET_PROFILE_TEST, BUDGET_PROFILE_PROD, BUDGET_PROFILE_UNLIMITED)
    if budget_profile not in valid_profiles:
        raise ValidationError(
            f"Invalid budget profile: {budget_profile}. "
            f"Must be one of: {', '.join(valid_profiles)}"
        )
    general_budget = get_general_budget(budget_profile)
    
    config_lines = [
        "# LiteLLM Configuration",
        "# Auto-generated by setup.py",
        "# Models are configured through Admin UI: http://localhost:4000/ui",
        "",
        "# General behavior settings",
        f"# Budget profile: {budget_profile}",
        "general_settings:",
        f"  max_budget: {general_budget}",
        "  budget_duration: \"monthly\"",
        "  master_key: os.environ/LITELLM_MASTER_KEY",
        "  database_url: os.environ/DATABASE_URL  # Required for store_model_in_db",
        "  store_model_in_db: true  # Enabled for Admin UI and model management",
        "  ui_username: os.environ/UI_USERNAME",
        "  ui_password: os.environ/UI_PASSWORD",
        "  # drop_params: true  # Remove incompatible parameters for Azure OpenAI compatibility",
        "  # NOTE: drop_params is safe - it only removes parameters not supported by specific provider",
        "  # For Azure: removes Azure-incompatible params, for Claude: removes Claude-incompatible params",
        "  # Model settings are NOT affected - only request parameters are filtered",
        "  # Uncomment if needed for Azure compatibility issues",
        "  # Custom callback for tool call validation (filters orphaned tool messages for Azure)",
        "  # Using both success_callback and pre_call_hook to ensure callback is called",
        "  success_callback: [\"litellm_callbacks.tool_call_validator.ToolCallValidator\"]",
        "  pre_call_hook: [\"litellm_callbacks.tool_call_validator.ToolCallValidator\"]",
        "  # Retry configuration for handling rate limits (429 errors)",
        "  # Strategy: Delayed retry with exponential backoff - agent waits and gets response later, no error shown",
        "  num_retries: 3  # Retry up to 3 times",
        "  max_retries: 3  # Also set max_retries for models configured via UI (overrides default 0)",
        "  timeout: 600  # Request timeout: 10 minutes (allows retries with delays)",
        "  # Retry delay configuration (configurable, delayed retries)",
        "  # LiteLLM uses Retry-After header from 429 responses for delay",
        "  # If Retry-After not present, uses exponential backoff: base_delay * (2 ^ retry_count)",
        "  # Default behavior: waits Retry-After seconds (usually 60s for Anthropic) before retry",
        "  # How it works (IMPORTANT - agent gets response, not error):",
        "  # 1. When LiteLLM receives 429 error, it does NOT return error to client immediately",
        "  # 2. LiteLLM automatically reads Retry-After header from 429 responses",
        "  # 3. Waits the specified time (Retry-After header value, or exponential backoff if not present)",
        "  # 4. Retries the request automatically (client/agent continues waiting)",
        "  # 5. With 3 retries + delays: total wait time depends on Retry-After values",
        "  # 6. Only after ALL retries fail, error is returned to client",
        "  # 7. If any retry succeeds, agent gets successful response (no error shown)",
        "  # 8. Exponential backoff: delay = base_delay * (2 ^ retry_count) if Retry-After not present",
        "  # Rate limiting: prevent exceeding API quotas",
        "  # Note: Rate limits vary by provider (Anthropic: 50k ITPM, Azure: per-deployment)",
        "  # Configurable retry: adjust num_retries and timeout based on your needs",
        "  # max_parallel_requests: 10  # Uncomment and adjust if needed to limit concurrent requests",
        "",
        "# Router settings - applies to ALL models (including UI-configured models)",
        "# This ensures retry settings work for models configured via Admin UI",
        "router_settings:",
        "  # Retry configuration (configurable, delayed retries)",
        "  # IMPORTANT: These settings apply to all models, including UI-configured ones",
        "  # retry_after: Base delay in seconds before retry (used if Retry-After header not present)",
        "  # LiteLLM automatically uses Retry-After header from 429 responses when available",
        "  # If Retry-After not present, uses retry_after value or exponential backoff",
        "  # Note: Anthropic rate limit is 50k ITPM - retry_after should be >= 60s to allow limit reset",
        "  # IMPORTANT: After successful retry, next request may still hit limit if previous request used most of 50k ITPM",
        "  # Increasing retry_after to 120s (2 minutes) gives more time for limit to reset between retries",
        "  num_retries: 5  # Number of retries (applies to all models including UI)",
        "  retry_after: 120  # Base delay in seconds between retries (120s = 2min allows token limit to fully reset)",
    ]
    
    # Write to file
    # Try to use FileRepository, fallback to direct file operations
    try:
        from pathlib import Path
        from .infrastructure.file_repository import FileRepository
        from .core.exceptions import FileOperationError
        
        repo = FileRepository(Path("."))
        repo.write_text(Path("config.yaml"), "\n".join(config_lines))
    except (ImportError, AttributeError):
        # Fallback to old implementation
        try:
            with open("config.yaml", "w", encoding="utf-8") as f:
                f.write("\n".join(config_lines))
        except (IOError, OSError, PermissionError) as e:
            from .utils import print_error
            from .core.exceptions import FileOperationError
            print_error(f"Error writing config.yaml file: {e}")
            raise FileOperationError(f"Failed to create config.yaml file: {e}") from e
    
    print_success("config.yaml created")
